# Week 7 - Natural Language Processing, Part II

### This week you will...

* start digging into a variety of model formats that are used in training models to understand context in sequence. In the last couple of weeks you looked first at Tokenizing words to get numeric values from them, and then using Embeddings to group words of similar meaning depending on how they were labelled. This gave you a good, but rough, sentiment analysis -- words such as 'fun' and 'entertaining' might show up in a positive movie review, and 'boring' and 'dull' might show up in a negative one. But sentiment can also be determined by the sequence in which words appear. For example, you could have 'not fun', which of course is the opposite of 'fun'.&#x20;
* learn about using natural language processing (NLP) models for predictions. Given a body of words, you could conceivably predict the word most likely to follow a given word or phrase, and once you've done that, to do it again, and again. With that in mind, you'll build a poetry generator. It's trained with the lyrics from traditional Irish songs, and can be used to produce beautiful-sounding verse of it's own.

### Learning Resources

* Week 3 and 4 of the course [Natural Language Processing in TensorFlow](https://www.coursera.org/learn/natural-language-processing-tensorflow)

### Until next week you should...

* complete week 1 and week 2 of the course [Sequences, Time Series and Prediction](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction), including the provided assignments
* look at [ArXive](https://arxiv.org/) or [ArXive Sanity](http://www.arxiv-sanity.com/), and [Papers With Code](https://paperswithcode.com/) for papers dealing with a modeling task similar to your project.
