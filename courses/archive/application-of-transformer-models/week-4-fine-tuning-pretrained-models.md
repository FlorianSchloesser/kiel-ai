# Week 4 - Fine-Tuning Pretrained Models

### This week you will...

* learn how to fine-tune a Hugging Face model with your own data

### Learning Resources

{% file src="../../.gitbook/assets/220511_Fine-Tuning Transformers.pdf" %}

### Until next week you should...

* [x] complete [chapter 4](https://huggingface.co/course/chapter4/1) (Sharing Models and Tokenizers) and [chapter 5](https://huggingface.co/course/chapter5/1) (The Datasets Library) of the Hugging Face course
* [x] do a literature review on the task of you project:
  * Search for transformer models applied to similar problems
  * Focus on the structure of the input and of the output
  * Are there pretrained models that you can use?
  * Which type of model is best suited? Do you need tokenization?
  * Do you need a type of embedding layer?
