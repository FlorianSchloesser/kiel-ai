# Week 4 - Vector Space Models

For this week you should have gone through the lectures of week 3 of the first Coursera course on NLP and the assignment. [https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/week/3](https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/week/3)

In this week we dive into representing our words as words vectors. Remember any ML Algorithm requires its input in a mathematical forms i.e in digits. The last two weeks we assiociated to each tweet two digits - one for posive sentiment and one for negative sentiment - and fed that vector in our models. From now on we will try a different approach indepedent from sentiment analysis ahd thus more general.

For that we encode each word as a vector. Thus we need a dictionary mapping each word to its corresponding vector. In general we do not know what is the best vector to represent a word. So we have also to learn that. Luckily there are a lot of pretrained word embeddings online and we can normally use one of those :slight\_smile:&#x20;

For the next week you should go through all the course videos,  the assignment and the quiz of week 4 of course 1 in the NLP specialization. Take notes and notice if you have any questions about the material. In the next meeting we will discuss these.

[https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/week/4](https://www.coursera.org/learn/classification-vector-spaces-in-nlp/home/week/4)

To quote the NLP tutor: "And remember to have fun".&#x20;

See you next week :slight\_smile:&#x20;

